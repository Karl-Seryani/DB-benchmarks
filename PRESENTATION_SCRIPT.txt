=================================================================
15-MINUTE PRESENTATION SCRIPT
ClickHouse vs Elasticsearch: A Comparative Analysis
=================================================================

SLIDE 1: Title (30 seconds)
----------------------------
"Good [morning/afternoon]. Today I'll be presenting my comparative analysis 
of ClickHouse versus Elasticsearch for analytical workloads. Over the past few 
weeks, I've conducted extensive benchmarking across three datasets - ranging from 
160,000 to 50 million rows - to understand how these databases perform in real-world scenarios."

SLIDE 2: Problem Statement (45 seconds)
----------------------------------------
"The motivation for this project came from a simple question: When should you use 
ClickHouse versus Elasticsearch? Both are popular choices for analytics, but they're 
built on fundamentally different architectures. ClickHouse is a columnar database 
optimized for OLAP workloads, while Elasticsearch is document-oriented, originally 
designed for search. I wanted to test how these architectural differences translate 
to real performance metrics."

SLIDE 3: Datasets Overview (1 minute)
-------------------------------------
"I tested three datasets with increasing scale:

First, a synthetic healthcare dataset with 160,000 rows across three tables - 
patients, medical events, and IoT telemetry. This represents a typical 
small-to-medium enterprise workload.

Second, NYC taxi trip data with 13 million authentic records from early 2024. 
This is real-world data from the NYC Taxi Commission.

And third - and this is where it gets interesting - I scaled up to 50 million 
rows using the same NYC taxi data. This enterprise-scale dataset really pushed 
both systems to their limits."

SLIDE 4: Storage Efficiency - Healthcare (1 minute)
---------------------------------------------------
"Let's start with storage. On the healthcare dataset, ClickHouse used just 
2.09 MiB compared to Elasticsearch's 31.35 MB. That's a 15x compression advantage. 
You can see the breakdown here - across all three tables, ClickHouse consistently 
uses less space. This matters because storage costs money, especially in cloud environments."

SLIDE 5: Storage Efficiency - NYC 13M (45 seconds)
--------------------------------------------------
"The pattern continues with the NYC dataset. ClickHouse: 206 MiB. Elasticsearch: 
1.72 GB. That's 8.5x better compression. What's interesting is that as data scales, 
ClickHouse's advantage becomes even more pronounced."

SLIDE 6: Storage Efficiency - NYC 50M (1 minute)
------------------------------------------------
"At 50 million rows, ClickHouse uses 823 MiB while Elasticsearch needs 6.65 GB.  
The compression ratio holds at 8.27x. More importantly, look at the ingestion speed: 
ClickHouse loaded all 50 million rows in under 9 minutes at 95,000 rows per second. 
Elasticsearch took 102 minutes - that's 11.6x slower. In production, this means 
ClickHouse can ingest data from real-time streams much more efficiently."

SLIDE 7: Query Performance Matrix - Healthcare (1.5 minutes)
-----------------------------------------------------------
"Now for the interesting part - query performance. I ran seven different benchmark 
types to test various analytical patterns.

Looking at the healthcare results: ClickHouse dominated in most categories. 
Multi-level GROUP BY queries were 54x faster. Time-series aggregations were 
212x faster. Complex analytical queries with JOIN operations? 23x faster.

But notice - Elasticsearch won on simple aggregations and filter operations. 
This makes sense given its inverted index structure, which is optimized for 
these exact use cases."

SLIDE 8: Query Performance Matrix - NYC 13M (1 minute)
------------------------------------------------------
"At 13 million rows, the patterns shift slightly. ClickHouse still dominates 
time-series operations - 11x faster - and complex queries. But Elasticsearch's 
caching really shines here on repeated queries, bringing down those filter times 
significantly. This is where understanding your query patterns matters for 
database selection."

SLIDE 9: Query Performance Matrix - NYC 50M (1.5 minutes)
---------------------------------------------------------
"Here's where it gets really interesting. At 50 million rows, I tested a different  
type of workload - selective queries with time-based filters. This mimics real-world 
scenarios where you're analyzing recent data, not the entire historical dataset.

Notice how Elasticsearch dominates here? This reveals its core strength: when you're  
filtering down to a subset of data, Elasticsearch's inverted indexes are incredibly 
efficient. The 13M results showed full-table scans where ClickHouse excels. These  
50M results show filtered queries where Elasticsearch shines.

This is the key insight: ClickHouse wins for full historical analytics. Elasticsearch 
wins for recent, filtered data analysis. The architecture determines the use case."

SLIDE 10: Interactive Demo (2 minutes)
--------------------------------------
[Navigate to Interactive Terminal]

"Let me show you a quick live demonstration. I've built this interactive terminal 
where I can run queries against the actual databases.

[Select ClickHouse + NYC 50M]
[Click Example 1]

"Here's a simple query grouping by payment type. Watch the execution time...
[Execute] 

ClickHouse returns this in about 60-80 milliseconds across 50 million rows.

[Switch to Elasticsearch]
[Click Example 1]

Now the same query in Elasticsearch...
[Execute]

Comparable for this simple aggregation. But watch what happens with a more complex query..."

[Show Example 3 for both - the time-series query to demonstrate the difference]

SLIDE 11: Key Takeaways (2 minutes)
-----------------------------------
"So what did I learn? The answer isn't 'X is better than Y' - it's more nuanced.

Choose ClickHouse when you need:
- Full historical dataset analytics (scanning billions of rows)
- Complex SQL with JOINs, subqueries, and window functions
- Extreme storage efficiency (8-15x compression)
- Fast bulk data ingestion (10x faster loading)
- Time-series analytics on complete datasets

Choose Elasticsearch when you need:
- Recent, filtered data analysis (last 7/30/90 days)
- Full-text search combined with analytics
- High-cardinality aggregations with selective filters
- Document-oriented, semi-structured data
- Geospatial queries and filtering

The critical insight from this project: **Query pattern matters more than data size**.
My 13M test showed ClickHouse winning with full scans. My 50M test showed Elasticsearch 
winning with selective filters. Both are correct - for their specific workload."

SLIDE 12: Conclusions (1 minute)
--------------------------------
"In conclusion, this project demonstrated measurable performance differences between 
columnar and document-oriented databases. ClickHouse's columnar storage provides 
significant advantages for analytical workloads - both in storage efficiency and 
query performance at scale. However, Elasticsearch's strengths in filtered aggregations 
and its ecosystem shouldn't be dismissed.

For the healthcare and NYC datasets, I found ClickHouse to be the better choice for 
pure analytics, while Elasticsearch would excel in hybrid search-analytics scenarios.

Thank you. I'm happy to take questions."

=================================================================
TIMING BREAKDOWN:
- Introduction: 0:30
- Problem Statement: 0:45
- Datasets: 1:00
- Storage (3 slides): 2:45
- Query Performance (3 slides): 4:00
- Interactive Demo: 2:00
- Takeaways: 2:00
- Conclusion: 1:00
TOTAL: 14:00 minutes (with 1 minute buffer)
=================================================================

STREAMLINED SLIDE ORDER (12 slides total):
1. Title
2. Problem Statement / Motivation
3. Datasets Overview
4. Storage Efficiency - Healthcare
5. Storage Efficiency - NYC 13M  
6. Storage Efficiency - NYC 50M
7. Query Performance - Healthcare
8. Query Performance - NYC 13M
9. Query Performance - NYC 50M
10. Interactive Terminal (Live Demo)
11. Key Takeaways
12. Conclusions

REMOVED SLIDES:
- Architecture slide (not critical for presentation)
- mpathic comparison (confusing, not core to story)
- Detailed breakdowns (too granular)
- Individual benchmark slides (covered in matrix)
- Scalability deep-dive (covered in storage)
- Live storage demo (redundant)
- Multiple intro slides (consolidated)

