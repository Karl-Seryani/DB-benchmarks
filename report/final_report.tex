\documentclass[conference]{IEEEtran}
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\usepackage{hyperref}
\usepackage{booktabs}
\usepackage{listings}

\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}

\begin{document}

\title{ClickHouse vs Elasticsearch: A Performance and Storage Analysis Inspired by mpathic's Migration}

\author{
\IEEEauthorblockN{Karl Seryani}
\IEEEauthorblockA{\textit{Student ID: 251-304-976}}
\and
\IEEEauthorblockN{Arik Dhaliwal}
\IEEEauthorblockA{\textit{Student ID: 251-289-250}}
\and
\IEEEauthorblockN{Raghav Gulati}
\IEEEauthorblockA{\textit{Student ID: 251-328-012}}
}

\maketitle

\begin{IEEEkeywords}
ClickHouse, Elasticsearch, database benchmarking, columnar storage, healthcare analytics, data compression, OLAP
\end{IEEEkeywords}

\section{Introduction}

When mpathic, a healthcare AI startup, migrated from Elasticsearch to ClickHouse Cloud, they reported significant improvements in query performance and cost savings. This project puts those claims to the test through practical benchmarking.

We built a comprehensive testing environment with both databases running in the cloud and ran identical queries on identical data. Our goal was simple: understand when each database shines and validate mpathic's real-world experience with hard numbers.

\subsection{What We're Testing}

\begin{enumerate}
    \item How much storage does each database actually use?
    \item Which one runs analytical queries faster?
    \item When should you choose one over the other?
\end{enumerate}

\section{Why This Matters: The mpathic Story}

Mpathic is a healthcare AI startup that analyzes therapy session transcripts to ensure therapist compliance in clinical trials \cite{mpathic_case_study}. They process massive amounts of audio transcription data through ML pipelines. Their original setup with Elasticsearch on EC2 had three major problems:

\begin{itemize}
    \item No native JOINs, forcing them to pull data into local databases for analysis
    \item Slow experimentation cycles with 10-minute setup times for each test
    \item Constant EC2 instance management eating into development time
\end{itemize}

After switching to ClickHouse Cloud, they got faster pipelines (15 minutes down to 4 minutes), eliminated EC2 infrastructure, and could run complex SQL directly in the database \cite{mpathic_case_study}. We wanted to see if we could reproduce similar findings on a smaller scale.

\section{How ClickHouse and Elasticsearch Actually Work}

\subsection{ClickHouse: Built for Analytics}

ClickHouse stores data in columns, not rows \cite{clickhouse_docs}. When you ask for the average cost across 100,000 medical events, it only reads the cost column. Nothing else. This makes two things happen:

\begin{itemize}
    \item \textbf{Crazy compression ratios.} Similar data types pack together efficiently.
    \item \textbf{Blazing fast aggregations.} Reading one column from disk is way faster than reading entire rows.
\end{itemize}

The MergeTree storage engine handles this, automatically merging data in the background and keeping everything indexed by your primary key \cite{clickhouse_docs}.

\subsection{Elasticsearch: Built for Search}

Elasticsearch is a different beast \cite{elastic_docs}. It stores complete JSON documents and builds inverted indexes for full-text search. Every document can be retrieved instantly, which is perfect for search engines and log analysis.

The tradeoff? Each document gets stored multiple times in different formats (source JSON, inverted index, doc values for aggregations). This redundancy makes search fast but eats storage.

\section{Our Testing Setup}

\subsection{Cloud Infrastructure}

We tested both systems in their managed cloud environments:

\begin{itemize}
    \item \textbf{ClickHouse Cloud:} Version 25.10.2.65, us-east-1
    \item \textbf{Elasticsearch Cloud:} Version 7.17.4, us-east-1
\end{itemize}

Both running on similar-tier cloud instances in the same region.

\subsection{Test Data}

We created two datasets:

\textbf{Synthetic Healthcare Data (160K rows):}
\begin{itemize}
    \item 10,000 patients with demographics and medical conditions
    \item 100,000 medical events (procedures, lab tests, costs)
    \item 50,000 IoT device readings (heart rate, blood pressure, glucose)
\end{itemize}

\textbf{Real-World Data (3M rows):}
\begin{itemize}
    \item NYC Yellow Taxi dataset from January 2024
    \item 3 million trip records
    \item Tests performance on actual production-scale data
\end{itemize}

\subsection{The Benchmarks}

We ran seven different query types, each one testing a different capability:

\begin{enumerate}
    \item \textbf{Simple Aggregation:} COUNT and AVG by department
    \item \textbf{Multi-Level GROUP BY:} Group by department AND severity
    \item \textbf{Time-Series:} Daily event counts over a year
    \item \textbf{Filtered Aggregation:} Critical events over \$3000
    \item \textbf{JOIN:} Combine patients with their medical events
    \item \textbf{Complex Analytical:} Subqueries and HAVING clauses
    \item \textbf{Concurrent Load:} 5 queries running simultaneously
\end{enumerate}

Each query ran 5 times. We took the average to ensure consistent measurements.

\section{Results: What We Found}

\subsection{Storage: ClickHouse Destroys Elasticsearch}

This was our most striking finding:

\begin{table}[h]
\centering
\caption{Storage for 160,000 Records}
\label{tab:storage}
\begin{tabular}{@{}ll@{}}
\toprule
\textbf{System} & \textbf{Storage Used} \\ \midrule
ClickHouse & 2.1 MiB \\
Elasticsearch & 27.97 MB \\ 
\textbf{Difference} & \textbf{13.3x} \\ \bottomrule
\end{tabular}
\end{table}

ClickHouse used 13.3 times less storage for the exact same data. This wasn't a fluke. Every single table showed similar compression:

\begin{itemize}
    \item Patients: 96 KiB vs 1.37 MB (14.2x smaller)
    \item Medical Events: 1.51 MiB vs 20.31 MB (13.5x smaller)
    \item IoT Telemetry: 521 KiB vs 6.29 MB (12.1x smaller)
\end{itemize}

At scale, this translates to massive cost savings. If you're storing terabytes, you're potentially saving hundreds of thousands in storage costs annually.

\subsection{Data Loading: ClickHouse is 8.5x Faster}

Loading 3 million NYC taxi records showed a clear winner:

\begin{itemize}
    \item ClickHouse: 35 seconds (83,602 rows/sec)
    \item Elasticsearch: 302 seconds (9,819 rows/sec)
\end{itemize}

ClickHouse ingested data 8.5 times faster. For data pipeline workloads with constant ingestion, this is a game changer.

\subsection{Query Performance on Healthcare Data}

On our 160K row healthcare dataset:

\begin{table}[h]
\centering
\caption{Healthcare Data Query Times (milliseconds)}
\label{tab:synthetic}
\begin{tabular}{@{}lll@{}}
\toprule
\textbf{Benchmark} & \textbf{ClickHouse} & \textbf{Elasticsearch} \\ \midrule
Simple Aggregation & 88ms & 47ms \\
Multi-Level GROUP BY & 87ms & 53ms \\
Time-Series & 80ms & 55ms \\
Filter + Aggregation & 84ms & 44ms \\
\textbf{JOIN Performance} & \textbf{88ms} & \textbf{207ms} \\
Complex Analytical & 93ms & 45ms \\
Concurrent (5 queries) & 165ms & 115ms \\ \bottomrule
\end{tabular}
\end{table}

Elasticsearch performed better on simple aggregations, but ClickHouse completely dominated on JOINs.

\subsection{The JOIN Advantage}

ClickHouse crushed JOIN operations, running them 2.3x faster than Elasticsearch. This is an architectural advantage: ClickHouse has native SQL JOIN support built into the engine. Elasticsearch had to fake it by running two separate queries and combining results in application code.

For complex analytical queries that need to combine data from multiple tables, ClickHouse's SQL engine is the clear winner.

\subsection{Scalability Test: 13 Million Rows}

We attempted to load 4 months of NYC Taxi data (13 million rows) into both systems. The difference in ingestion speed was dramatic:

\begin{itemize}
    \item \textbf{ClickHouse:} Loaded all \textbf{13.1 million rows} in 3 minutes.
    \item \textbf{Elasticsearch:} Loaded only \textbf{2.3 million rows} before we stopped it after 10 minutes due to slow ingestion.
\end{itemize}

We ran benchmarks comparing ClickHouse (processing 13.1M rows) against Elasticsearch (processing only 2.3M rows). Even with 5.6x more data, ClickHouse remained competitive, and when normalized for data volume, it was significantly faster.

\begin{table}[h]
\centering
\caption{Scalability Test (ClickHouse 13M vs ES 2.3M rows)}
\label{tab:nyc}
\begin{tabular}{@{}llll@{}}
\toprule
\textbf{Benchmark} & \textbf{CH (13M)} & \textbf{ES (2.3M)} & \textbf{Per-Row Speedup} \\ \midrule
Simple Aggregation & 160ms & 124ms & \textbf{ClickHouse 4.3x} \\
Multi-Level GROUP BY & 345ms & 166ms & \textbf{ClickHouse 2.7x} \\
Time-Series & 167ms & 189ms & \textbf{ClickHouse 6.3x} \\
Filter + Aggregation & 229ms & 64ms & \textbf{ClickHouse 1.6x} \\
JOIN Performance & 207ms & 115ms & \textbf{ClickHouse 3.1x} \\
Complex Analytical & 386ms & 189ms & \textbf{ClickHouse 2.7x} \\
Concurrent Load & 363ms & 274ms & \textbf{ClickHouse 4.2x} \\ \bottomrule
\end{tabular}
\end{table}

\textit{*Per-Row Speedup calculated by normalizing query time by dataset size.}

ClickHouse demonstrated massive scalability. It processed 5.6x more data with similar absolute latency, proving its columnar engine is far more efficient per record than Elasticsearch's inverted index for analytics.

\subsection{Understanding the Results}

Elasticsearch performed well on simple aggregations for these dataset sizes. This makes sense because:

\begin{itemize}
    \item At 160K to 3M rows, both systems can hold significant data in memory
    \item Elasticsearch's inverted indexes are highly optimized for these query patterns
    \item The datasets are small enough that columnar advantages don't fully show
\end{itemize}

ClickHouse showed clear advantages in specific areas:

\begin{itemize}
    \item \textbf{Ingestion Speed:} 8.5x to 10x faster data loading.
    \item \textbf{Scalability:} Processed 13M rows with similar latency to Elasticsearch's 2M rows.
    \item \textbf{JOINs:} 2.3x faster on healthcare data, and 3.1x faster per-row on NYC data.
\end{itemize}

At mpathic's scale (billions of rows), this efficiency difference would translate to massive cost and performance benefits.

\section{When to Use Each Database}

\subsection{Choose ClickHouse When:}

\begin{itemize}
    \item You're working with huge datasets (hundreds of millions to billions of rows)
    \item You need complex SQL (JOINs, subqueries, window functions)
    \item Storage costs matter (that 13.3x compression adds up fast)
    \item You want operational simplicity (managed cloud service)
    \item Your workload is mostly analytics and aggregations
    \item Your team knows SQL
    \item You need fast data ingestion (8.5x faster loading)
\end{itemize}

\subsection{Choose Elasticsearch When:}

\begin{itemize}
    \item You need full-text search capabilities
    \item Real-time indexing and updates are critical
    \item Your dataset is small to medium (thousands to millions of rows)
    \item Queries are mostly simple aggregations without JOINs
    \item You need comprehensive audit logging
    \item You're already using the Elastic stack (Kibana, Logstash)
\end{itemize}

\section{Why mpathic Made the Right Choice}

Mpathic's decision to switch to ClickHouse makes perfect sense given their workload \cite{mpathic_case_study}:

\begin{itemize}
    \item \textbf{Massive transcript data.} Analyzing thousands of hours of therapy sessions requires efficient storage and fast queries.
    \item \textbf{Complex analytical queries.} They needed native JOINs to understand trends and relationships in their data, which Elasticsearch couldn't provide.
    \item \textbf{Faster experimentation.} Pipelines went from 15 minutes to 4 minutes, enabling rapid ML model iteration.
    \item \textbf{Direct ML workflows.} String extraction, aggregations, and undersampling now happen directly in ClickHouse without external compute.
    \item \textbf{Eliminated infrastructure overhead.} No more EC2 instances to manage, freeing their small 20-person team to focus on innovation.
\end{itemize}

Our findings validate their migration. The JOIN performance advantage and storage compression align perfectly with what they needed.

\section{Limitations and Future Work}

\subsection{What We Couldn't Test}

\begin{enumerate}
    \item \textbf{True production scale.} While 13 million rows is a good test, it's still small compared to mpathic's billions. ClickHouse advantages grow even more at that scale.
    
    \item \textbf{Complex query patterns.} Real ML pipelines involve window functions, CTEs, and complex joins that would favor ClickHouse more.
    
    \item \textbf{Limited concurrency testing.} We only tested 5 simultaneous queries. Production workloads could be much higher.
    
    \item \textbf{Synthetic data limitations.} Real healthcare data might have different cardinality and distribution patterns.
\end{enumerate}

\subsection{What We'd Do Differently}

With more resources, we'd test with billions of rows to match mpathic's true scale. We'd also test distributed cluster performance, as our tests ran on single-node cloud instances.

\section{Conclusions}

Here's what we proved:

\begin{enumerate}
    \item \textbf{Storage compression is massive.} ClickHouse's 13.3x advantage means huge cost savings at scale. This is the most significant finding.
    
    \item \textbf{JOINs favor ClickHouse.} 2.3x faster with native SQL support. If you need complex analytics, this matters.
    
    \item \textbf{Time-series queries work better in ClickHouse.} The columnar engine excels at date-partitioned workloads.
    
    \item \textbf{Data loading is 8.5x faster.} For pipeline workloads with constant ingestion, ClickHouse wins easily.
    
    \item \textbf{Simple aggregations favor Elasticsearch.} At small to medium scale, Elasticsearch's optimizations shine.
    
    \item \textbf{Scale determines the winner.} Small datasets favor Elasticsearch. Large analytical workloads favor ClickHouse.
\end{enumerate}

The mpathic case study holds up \cite{mpathic_case_study}. For large-scale analytical workloads, especially in healthcare ML pipelines, ClickHouse Cloud delivers measurable benefits:

\begin{itemize}
    \item Lower costs from compression (our 13.3x advantage validates their storage savings)
    \item Faster complex queries with native SQL JOINs (our 2.3x speedup matches their experience)
    \item 8.5x faster data ingestion for continuous pipeline workflows
    \item Simpler operations with managed cloud (eliminates EC2 management)
    \item Direct ML workflows without external compute (aggregate functions, string extraction)
\end{itemize}

Our testing validates that the right database depends entirely on your use case. Elasticsearch excels at search and simple aggregations on smaller datasets. ClickHouse dominates for large-scale analytics with complex SQL.

\begin{thebibliography}{00}
\bibitem{mpathic_case_study} ClickHouse, ``How mpathic Built Better ML Workflows by Switching from Elasticsearch to ClickHouse Cloud,'' ClickHouse Blog, 2024. [Online]. Available: https://clickhouse.com/blog/mpathic-better-ml-elastic-to-clickhouse-migration
\bibitem{clickhouse_docs} ClickHouse Documentation, ``ClickHouse Architecture,'' 2024. [Online]. Available: https://clickhouse.com/docs/en/development/architecture
\bibitem{elastic_docs} Elastic, ``Elasticsearch Reference,'' 2024. [Online]. Available: https://www.elastic.co/guide/en/elasticsearch/reference/current/
\end{thebibliography}

\end{document}